from argparse import ArgumentParser
import galois
import numpy as np
import time
import math
from tqdm import tqdm

def threshold(m,t):
   return min(4*m,2*t)

HW = np.array([bin(i).count("1") for i in range(2**13)], dtype="uint32")
HW2 = np.array([(bin(i).count("1"))%2 for i in range(2**13)], dtype="uint32")

Classic_McEliece_polys = {9:  [1, 0, 0, 0, 0, 0, 0, 0, 1, 1],
                          10: [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
                          12: [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
                          13: [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1]}

"""Those are the polynomials that are used to define the finite fields of order 2**m for m in [9,10,12,13]  in Classic_McEliece
"""



def reconstruct_seq_from_poly(L,poly,i_start,m):
    """ L is a noisy LFSR sequence generated by the polynomial poly of degree m. We assume that L[i_start:i_start+2*m] is non-noisy.
    Output is a pair Lp, e where Lp is the original non-noisy sequence and e is the Hamming distance between Lp and L. 
    """
    #computing forward sequence generated by poly
    LFSR_fw=galois.FLFSR(poly.reverse(),state=list(reversed(L[i_start : i_start + m])))
    seq_predicted=np.zeros(len(L),dtype=int)
    for i in range(i_start,len(L)):
        seq_predicted[i]=LFSR_fw.step()
    #compute backward sequence generated by poly
    LFSR_bw=galois.FLFSR(poly,state=L[i_start : i_start + m])
    for i in range(0,i_start+m):
        seq_predicted[i_start+m-1-i]=LFSR_bw.step()
    return seq_predicted,np.sum(L!=seq_predicted)
    
def recover_poly_by_maj_vote(L,t,m):
    """ L is a noisy LFSR sequence of length at least 2*t, m is the degree of the polynomial generating the non-noisy sequence. 
    
    recover_poly_by_maj_vote selects the most recurrent polynomial P of degree m (with a few more possible conditions, such as non-zero constant term) among Berlekamp-Massey (BM) outputs of sequences of length 2*m in L. cf Algorithm 3 in Submission 
    
    Output is a triplet P, e, Lp where Lp is reconstructed from P and L while e is the number of differences between P and Lp.
    Note that P is exact when the sequence is non-noisy and then can be obtained by calling the function with t=m (BM on 2m first values of L). Output is then P,0,L
    
    Output is [],-1,[] if no polynomial (BM-recovered) satisfied the required conditions 
    """
    Polys = np.array([galois.berlekamp_massey(L[i:i+2*m]) for i in range(2*t-2*m+1) ])
    #Polys = np.array([galois.berlekamp_massey(L[i:i+2*m]) for i in range(2*t-2*m) if len(galois.berlekamp_massey(L[i:i+2*m]))==m+1 and galois.berlekamp_massey(L[i:i+2*m]).coeffs[-1]==1])
    Filtred_polys=np.array([poly for poly in Polys if (len(poly)==m+1) and poly.is_irreducible()])
    #print(Filtred_polys)
    if len(Filtred_polys)==0:
        return [],len(L),[]
    else:
        polys_coeffs=np.array([poly.coeffs for poly in Filtred_polys])
        values, counts = np.unique(polys_coeffs, axis=0, return_counts=True)
        ind = np.argmax(counts)
        #TODO attention index_seq_correct doit etre sur toutes les fenetres
        for index_seq_correct in range(len(polys_coeffs)):
            if (polys_coeffs[index_seq_correct]==values[ind]).all():
                break
        GF2m = galois.GF(int(2**m), irreducible_poly=Classic_McEliece_polys[m])
        poly=galois.Poly(polys_coeffs[index_seq_correct],field=GF2m)
        seq_predicted,e=reconstruct_seq_from_poly(L,poly,index_seq_correct,m)
        return poly, e, seq_predicted


def recover_poly_by_closest_sequence(L,t,m):
    """
    L is a noisy LFSR sequence of length 2*t, m is the degree of the polynomial generating the non-noisy sequence.
     
    recover_poly_closest_sequence 
    -lists the polynomials P (of degree m with non-zero constant term and a few more possible conditions) arising as Berlekamp-Massey (BM) outputs of subsequences L[i:i+2*m] of length 2*m
    -reconstructs the theoretical non-noisy sequence Lp of length 2*t from P and the subsequence L[i:i+2*m]
    -selects the polynomial P such that the reconstructed non-noisy sequence is at minimal Hamming distance e to the orginal sequence
    cf Algorithm 4 in submission
    
    Output is the pair (P,e,Lp)
    """
    GF2m = galois.GF(int(2**m), irreducible_poly=Classic_McEliece_polys[m])
    #default inital values
    saved_poly=galois.Poly([0],field=GF2m) #meant to store candidates to the output polynomial P 
    error_seq=2*t+1 #meant to store the Hamming distance of the sequence generated by the candidate Polynomial with the original distance
    saved_seq_predicted=np.zeros(2*t,dtype=int)
    #int() cast for python2.x
    #for pow_step in range(max_pow_step):
        #step=2**pow_step
    #windows
    for i_start in range(0, 2 * t - 2 * m):
        poly = galois.berlekamp_massey(L[i_start:i_start + 2 * m])
        if len(poly)==m+1 and poly.is_irreducible():
          seq_predicted,e=reconstruct_seq_from_poly(L,poly,i_start,m)
          if e<error_seq:
             error_seq=e
             saved_poly=poly
             saved_seq_predicted=seq_predicted
    return saved_poly,error_seq,saved_seq_predicted
#Unnoisy case    
def recover_alpha(L,t,m):
    GF2m = galois.GF(2**m, irreducible_poly=Classic_McEliece_polys[m])
    resBM = recover_poly(L,t,m)
    #print(resBM[0])
    if resBM[1]:
        poly = galois.Poly(resBM[0],field=GF2m)
        #print(poly.is_irreducible())
        Alphas = poly.roots()
        return Alphas, poly, resBM[2]
    else:
        return [], -1,[]

    
def recover_alphas_noisy(L,t,m, method="closest_sequence"):
    GF2m = galois.GF(int(2**m), irreducible_poly=Classic_McEliece_polys[m])
    if method=="closest_sequence":
        poly,e,seq_predicted= recover_poly_by_closest_sequence(L,t,m)
    elif method=="maj_vote":
        poly, e, seq_predicted = recover_poly_by_maj_vote(L,t,m)
    else:
        print("unknown method ", method)
        return [], [],e,[]
    #TODO: select the most efficient threshold (currently 4*m)
    if e<threshold(m,t):
        poly = galois.Poly(poly.coefficients(),field=GF2m)
        Alphas = poly.roots()
        return Alphas, poly,e,seq_predicted
    else:
        #print("fail polynomial")
        return [], [],e,[]

def recover_alpha_beta(FL,L,t,m):
    GF2m = galois.GF(int(2**m), irreducible_poly=Classic_McEliece_polys[m])
    Alphas,poly,start_index=recover_alpha(L,t,m)
    W=L[:m]
    basisGF2=np.array([(2**i) for i in range(m)])
    savea,saveb=0,0
    if len(Alphas):
        for alpha in Alphas:
            #X = alpha[np.newaxis]**(np.arange(m)+start_index)
            X = alpha[np.newaxis]**(np.arange(m))
            #BasisX=[galois.Poly(c,field=GF2m) for c in np.eye(9)]
            BasisX=[GF2m(2**i) for i in range(m)]
            #TODO find a more efficient way 
            C = galois.GF2([[HW2[x*b] for b in BasisX] for x in X] )
            #https://stackoverflow.com/questions/62190107/solving-a-system-of-linear-equations-over-the-field-f2-with-python
            U=np.linalg.solve(C,W)
            #Need to correct W thanks to the sequence
            betag=GF2m(np.sum(np.array(U)*basisGF2))
            GLab=HW[((alpha[np.newaxis]**np.arange(2*t)).T)*betag]
            if (FL==GLab).all():
                savea,saveb=alpha,betag           
    return savea,saveb

        
def recover_alpha_beta_noisy(FL,L,t,m, method="closest_sequence"):
    """
    FL is a full Hamming sequence of weights, L is its restiction modulo 2.
    From the polynomial P in F_2[X] selected by recover_poly_by_maj_vote (if any, otherwise default result is [], [],[]), and its roots Alphas in F_{2m}, selects the root alpha in Alphas and a corresponding element beta in F_2m such that the reconstructed theoretical LFSR is obtained by Hamming weights modulo 2 of the sequence (alpha^i*beta)_i and such that FL is the Hamming weights of the sequence.
    cf. Algorithm ?? in ???  
    
    Output is a pair alpha, beta
    """
    GF2m = galois.GF(int(2**m), irreducible_poly=Classic_McEliece_polys[m])
    Alphas,poly,e,Lp=recover_alphas_noisy(L,t,m,method)
    #correct L thanks to poly
    if len(Alphas):
        Lp=galois.GF2(Lp)
        W=Lp[:m] ##
        basisGF2=np.array([(1<<i) for i in range(m)])
        savea,saveb=0,0
        for alpha in Alphas:
            #X = alpha[np.newaxis]**(np.arange(m)+start_index)
            X = alpha[np.newaxis]**(np.arange(m)) ##
            #BasisX=[galois.Poly(c,field=GF2m) for c in np.eye(9)]
            BasisX=[GF2m(int(1)<<i) for i in range(m)]
            #TODO find a more efficient way 
            C = galois.GF2([[HW2[x*b] for b in BasisX] for x in X] )
            #https://stackoverflow.com/questions/62190107/solving-a-system-of-linear-equations-over-the-field-f2-with-python
            U=np.linalg.solve(C,W)
            #Need to correct W thanks to the
            betag=GF2m(np.sum(np.array(U)*basisGF2))
            #print(alpha,betag,np.shape(W))
            GLab=HW[((alpha[np.newaxis]**np.arange(2*t)).T)*betag]
            #print(np.sum(FL!=GLab),e)
            #if np.sum(FL!=GLab)==0:
            if np.sum(FL!=GLab)==e:
                savea,saveb=alpha,betag
                #print("success?")
                return savea,saveb    
    return 0,0
    


def test_recover_poly(n, t, m, accuracy, nb_test):
    GF2m = galois.GF(int(2**m), irreducible_poly=Classic_McEliece_polys[m])
    for _ in range(nb_test):   
        pair=GF2m.Random(2)
        X = (pair[0, np.newaxis]**np.arange(2*t)).T
        Y = X*pair[1]
        #wt2 leakages
        L = np.array(HW2[Y])
        #add noise 
        noise = np.random.choice([0, 1], size=np.shape(L), p=[accuracy, (1 - accuracy)])
        L_noisy=galois.GF2(np.array(L^noise))
        L=galois.GF2(L)
        
        poly_noise_free,cnf,tmp=recover_poly(L,t,m) 
        poly_noise,cn,tmp=recover_poly(L_noisy,t,m) 
        
        print(poly_noise_free,poly_noise)
        if cn!=0 and cnf!=0:
            print((poly_noise_free==poly_noise).all())
        else: 
            print('false')


def compare_recover_poly_noisy(t, m, accuracy, nb_test):    
    GF2m = galois.GF(int(2**m), irreducible_poly=Classic_McEliece_polys[m])
    counter=[0,0]
    #success=0
    for _ in range(nb_test):
        pair=GF2m.Random(2)
        X = (pair[0, np.newaxis]**np.arange(2*t)).T
        Y = X*pair[1]
        FL = np.array(HW[Y])        
        #wt2 leakages
        L = np.array(HW2[Y])
        poly, e, seq_predicted = recover_poly_by_closest_sequence(galois.GF2(L),t,m)
        #add noise 
        noise = np.random.choice([0, -1,1], size=np.shape(L), p=[accuracy, (1 - accuracy)/2, (1 - accuracy)/2 ])
        FL_noisy=np.array(FL+noise)
        L_noisy=galois.GF2(np.array(FL_noisy%2))
        L=galois.GF2(L)
        
        polycs, ecs, seq_predictedcs = recover_poly_by_closest_sequence(L_noisy,t,m)
        polymv, emv, seq_predictedmv = recover_poly_by_maj_vote(L_noisy,t,m)
        if ecs >=0 and e >=0:
            if (np.array(poly.coeffs)==np.array(polycs.coeffs)).all():
                counter[0]+=1
        if emv >=0 and e >=0:
            if (np.array(poly.coeffs)==np.array(polymv.coeffs)).all():
                counter[1]+=1
    print(f"Over {nb_test} dor an {accuracy=} the closest method recovers {counter[0]} times the same poly as the non faulty sequence and the majority vote {counter[1]} times.")
                    
def test_noise_free(n, t, m, nb_test):
    GF2m = galois.GF(int(2**m), irreducible_poly=Classic_McEliece_polys[m])
    success=0
    for _ in range(nb_test):   
        pair=GF2m.Random(2)
        X = (pair[0, np.newaxis]**np.arange(2*t)).T
        Y = X*pair[1]
        #wt2 leakages
        L = galois.GF2(np.array(HW2[Y]))
        FL = np.array(HW[Y])        
        alpha,beta=recover_alpha_beta(FL,L,t,m)
        if(GF2m(pair[0])==alpha and GF2m(pair[1])==beta):
            success=success+1
        elif alpha==0 and beta==0:
            #print(pair[0])
            print(pair[0],galois.is_primitive_element(int(pair[0]),galois.Poly(Classic_McEliece_polys[m])))
    print(success/nb_test)


def test_noisy(t, m, accuracy, nb_test,method="closest_sequence"):
    GF2m = galois.GF(int(2**m), irreducible_poly=Classic_McEliece_polys[m])
    counter=[0,0,0]
    #success=0
    for _ in tqdm(range(nb_test)):
        pair=GF2m.Random(2)
        X = (pair[0, np.newaxis]**np.arange(2*t)).T
        Y = X*pair[1]
        FL = np.array(HW[Y])        
        #parity hamming weight leakages
        L = np.array(HW2[Y])
        #add noise 
        noise = np.random.choice([0, -1,1], size=np.shape(L), p=[accuracy, (1 - accuracy)/2, (1 - accuracy)/2 ])
        FL_noisy=np.array(FL+noise)
        L_noisy=galois.GF2(np.array(FL_noisy%2))
        L=galois.GF2(L)
        alpha,beta=recover_alpha_beta_noisy(FL_noisy,L_noisy,t,m,method)
        
        if alpha==0 and beta==0:
           counter[2]+=1
        else:
           success=(GF2m(pair[0])==alpha and GF2m(pair[1])==beta)
           if success:
              counter[0]+=1
           else:
              counter[1]+=1
    print(counter[0], " success and ", counter[1], " real fails over ", nb_test, " tests, among which ", nb_test-counter[2], " tests are admissible and ", counter[2], " tests have been ruled non-decidable")




        
if __name__ == "__main__":

    parser = ArgumentParser()
    parser.add_argument("nb_test",
                        type=int,
                        help="Number of elements in the support L")
    parser.add_argument("t",
                        type=int,
                        help="Error weight")
    parser.add_argument("m",
                        type=int,
                        help="Field degree: GF(2^m)")
    parser.add_argument("--accuracy",
                        type=float,
                        nargs="?",
                        default=1,
                        help="Side-channel distinguisher accuracy")
    args = parser.parse_args()
    
    nb_test, t, m = args.nb_test, args.t, args.m
    print(f"{nb_test=} {m=} {t=} {args.accuracy} ")

    
    test_noisy(t, m, args.accuracy, nb_test,method="closest_sequence")
    
       
